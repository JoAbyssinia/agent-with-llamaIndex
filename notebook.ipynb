{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# agent with Llamaindex\n",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Agent with LlamaIndex Notebook\n",
    "\n",
    "This notebook demonstrates the implementation of a simple agent using LlamaIndex framework. It showcases:\n",
    "\n",
    "- Setting up a local LLM model using Ollama\n",
    "- Creating custom functions for multiplication and weather data retrieval\n",
    "- Implementing an agent workflow with function tools\n",
    "- Demonstrating both stateless and stateful agent interactions\n",
    "- Using context objects to maintain conversation history\n",
    "\n",
    "The agent is able to perform mathematical operations and fetch weather information through defined function tools.\n"
   ],
   "id": "de954d0e10a2d293"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T03:01:53.961748Z",
     "start_time": "2025-05-25T03:00:44.859217Z"
    }
   },
   "cell_type": "code",
   "source": "pip install llama-index llama-index-llms-ollama",
   "id": "9d63177a08b614fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\r\n",
      "  Downloading llama_index-0.12.37-py3-none-any.whl (7.1 kB)\r\n",
      "Collecting llama-index-llms-ollama\r\n",
      "  Downloading llama_index_llms_ollama-0.5.6-py3-none-any.whl (7.9 kB)\r\n",
      "Collecting llama-index-cli<0.5,>=0.4.1\r\n",
      "  Downloading llama_index_cli-0.4.1-py3-none-any.whl (28 kB)\r\n",
      "Collecting llama-index-core<0.13,>=0.12.36\r\n",
      "  Downloading llama_index_core-0.12.37-py3-none-any.whl (7.7 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 7.7 MB 1.0 MB/s eta 0:00:01     |███▊                            | 890 kB 2.1 MB/s eta 0:00:04\r\n",
      "\u001B[?25hCollecting llama-index-readers-llama-parse>=0.4.0\r\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\r\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0\r\n",
      "  Downloading llama_index_readers_file-0.4.7-py3-none-any.whl (40 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 40 kB 808 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting llama-index-multi-modal-llms-openai<0.5,>=0.4.0\r\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\r\n",
      "Collecting nltk>3.8.1\r\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.5 MB 1.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting llama-index-llms-openai<0.4,>=0.3.0\r\n",
      "  Downloading llama_index_llms_openai-0.3.44-py3-none-any.whl (24 kB)\r\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0\r\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\r\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0\r\n",
      "  Downloading llama_index_agent_openai-0.4.8-py3-none-any.whl (14 kB)\r\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0\r\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\r\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0\r\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\r\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0\r\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.11-py3-none-any.whl (14 kB)\r\n",
      "Collecting ollama>=0.4.3\r\n",
      "  Downloading ollama-0.4.8-py3-none-any.whl (13 kB)\r\n",
      "Collecting openai>=1.14.0\r\n",
      "  Downloading openai-1.82.0-py3-none-any.whl (720 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 720 kB 2.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting eval-type-backport<0.3,>=0.2.0\r\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\r\n",
      "Collecting pillow>=9.0.0\r\n",
      "  Downloading pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 3.0 MB 1.5 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting nest-asyncio<2,>=1.5.8\r\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\r\n",
      "Collecting requests>=2.31.0\r\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 64 kB 2.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.36->llama-index) (4.6.2)\r\n",
      "Collecting aiohttp<4,>=3.8.6\r\n",
      "  Downloading aiohttp-3.12.0-cp39-cp39-macosx_11_0_arm64.whl (455 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 455 kB 1.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting pyyaml>=6.0.1\r\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 172 kB 1.6 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting deprecated>=1.2.9.3\r\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\r\n",
      "Collecting tiktoken>=0.7.0\r\n",
      "  Downloading tiktoken-0.9.0-cp39-cp39-macosx_11_0_arm64.whl (1.0 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.0 MB 1.8 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting httpx\r\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 73 kB 2.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting fsspec>=2023.5.0\r\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 199 kB 1.6 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting numpy\r\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 5.3 MB 1.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting tenacity!=8.4.0,<10.0.0,>=8.2.0\r\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\r\n",
      "Collecting typing-inspect>=0.8.0\r\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\r\n",
      "Collecting networkx>=3.0\r\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.6 MB 912 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting banks<3,>=2.0.0\r\n",
      "  Downloading banks-2.1.2-py3-none-any.whl (28 kB)\r\n",
      "Collecting wrapt\r\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\r\n",
      "Collecting pydantic>=2.8.0\r\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 444 kB 2.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting aiosqlite\r\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\r\n",
      "Collecting sqlalchemy[asyncio]>=1.4.49\r\n",
      "  Downloading sqlalchemy-2.0.41-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 2.1 MB 1.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting dataclasses-json\r\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\r\n",
      "Collecting dirtyjson<2,>=1.0.8\r\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\r\n",
      "Collecting filetype<2,>=1.2.0\r\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Collecting tqdm<5,>=4.66.1\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 78 kB 1.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: attrs>=17.3.0 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.36->llama-index) (23.1.0)\r\n",
      "Collecting async-timeout<6.0,>=4.0\r\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\r\n",
      "Collecting propcache>=0.2.0\r\n",
      "  Downloading propcache-0.3.1-cp39-cp39-macosx_11_0_arm64.whl (46 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 46 kB 651 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting multidict<7.0,>=4.5\r\n",
      "  Downloading multidict-6.4.4-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0\r\n",
      "  Downloading yarl-1.20.0-cp39-cp39-macosx_11_0_arm64.whl (95 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 95 kB 848 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting aiosignal>=1.1.2\r\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Collecting frozenlist>=1.1.1\r\n",
      "  Downloading frozenlist-1.6.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 122 kB 1.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: platformdirs in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.5.1)\r\n",
      "Collecting griffe\r\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 129 kB 2.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: jinja2 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (3.1.2)\r\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13\r\n",
      "  Downloading llama_cloud-0.1.22-py3-none-any.whl (265 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 265 kB 1.9 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting certifi>=2024.7.4\r\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 159 kB 1.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: anyio in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (3.7.0)\r\n",
      "Collecting httpcore==1.*\r\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 78 kB 845 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: idna in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from httpx->llama-index-core<0.13,>=0.12.36->llama-index) (3.4)\r\n",
      "Collecting h11>=0.16\r\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\r\n",
      "Collecting pypdf<6.0.0,>=5.1.0\r\n",
      "  Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 303 kB 612 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting pandas\r\n",
      "  Downloading pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 11.3 MB 713 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting beautifulsoup4<5.0.0,>=4.12.3\r\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 187 kB 1.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting striprtf<0.0.27,>=0.0.26\r\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.4.1)\r\n",
      "Collecting llama-parse>=0.5.0\r\n",
      "  Downloading llama_parse-0.6.23-py3-none-any.whl (4.9 kB)\r\n",
      "Collecting llama-cloud-services>=0.6.23\r\n",
      "  Downloading llama_cloud_services-0.6.23-py3-none-any.whl (37 kB)\r\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1\r\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\r\n",
      "Collecting platformdirs\r\n",
      "  Downloading platformdirs-4.3.8-py3-none-any.whl (18 kB)\r\n",
      "Collecting click<9.0.0,>=8.1.7\r\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 98 kB 1.0 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting regex>=2021.8.3\r\n",
      "  Downloading regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl (284 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 284 kB 836 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting joblib\r\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 307 kB 1.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: sniffio in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.0)\r\n",
      "Collecting jiter<1,>=0.4.0\r\n",
      "  Downloading jiter-0.10.0-cp39-cp39-macosx_11_0_arm64.whl (312 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 312 kB 1.1 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting typing-extensions>=4.5.0\r\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 45 kB 944 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting distro<2,>=1.7.0\r\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: exceptiongroup in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.36->llama-index) (1.1.1)\r\n",
      "Collecting typing-inspection>=0.4.0\r\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\r\n",
      "Collecting pydantic-core==2.33.2\r\n",
      "  Downloading pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl (1.9 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 1.9 MB 1.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting annotated-types>=0.6.0\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Collecting charset-normalizer<4,>=2\r\n",
      "  Downloading charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl (201 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 201 kB 1.3 MB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting urllib3<3,>=1.21.1\r\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 128 kB 800 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting greenlet>=1\r\n",
      "  Downloading greenlet-3.2.2-cp39-cp39-macosx_11_0_universal2.whl (266 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 266 kB 567 kB/s eta 0:00:01\r\n",
      "\u001B[?25hCollecting mypy-extensions>=0.3.0\r\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\r\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\r\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 50 kB 396 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: packaging>=17.0 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.36->llama-index) (23.1)\r\n",
      "Collecting colorama>=0.4\r\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.36->llama-index) (2.1.2)\r\n",
      "Collecting tzdata>=2022.7\r\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 347 kB 901 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.8.2)\r\n",
      "Collecting pytz>=2020.1\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "\u001B[K     |████████████████████████████████| 509 kB 588 kB/s eta 0:00:01\r\n",
      "\u001B[?25hRequirement already satisfied: six>=1.5 in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.16.0)\r\n",
      "Installing collected packages: typing-extensions, wrapt, urllib3, typing-inspection, pydantic-core, propcache, mypy-extensions, multidict, h11, frozenlist, colorama, charset-normalizer, certifi, annotated-types, yarl, typing-inspect, tqdm, sqlalchemy, requests, regex, pydantic, platformdirs, marshmallow, joblib, httpcore, griffe, greenlet, eval-type-backport, deprecated, click, async-timeout, aiosignal, aiohappyeyeballs, tiktoken, tenacity, pyyaml, pillow, numpy, nltk, networkx, nest-asyncio, jiter, httpx, fsspec, filetype, distro, dirtyjson, dataclasses-json, banks, aiosqlite, aiohttp, openai, llama-index-core, python-dotenv, llama-index-llms-openai, llama-cloud, tzdata, pytz, llama-index-agent-openai, llama-cloud-services, striprtf, pypdf, pandas, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, beautifulsoup4, ollama, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-cli, llama-index-llms-ollama, llama-index\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing-extensions 4.6.2\r\n",
      "    Uninstalling typing-extensions-4.6.2:\r\n",
      "      Successfully uninstalled typing-extensions-4.6.2\r\n",
      "  Attempting uninstall: platformdirs\r\n",
      "    Found existing installation: platformdirs 3.5.1\r\n",
      "    Uninstalling platformdirs-3.5.1:\r\n",
      "      Successfully uninstalled platformdirs-3.5.1\r\n",
      "  Attempting uninstall: pyyaml\r\n",
      "    Found existing installation: PyYAML 6.0\r\n",
      "    Uninstalling PyYAML-6.0:\r\n",
      "      Successfully uninstalled PyYAML-6.0\r\n",
      "  Attempting uninstall: nest-asyncio\r\n",
      "    Found existing installation: nest-asyncio 1.5.6\r\n",
      "    Uninstalling nest-asyncio-1.5.6:\r\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\r\n",
      "  Attempting uninstall: beautifulsoup4\r\n",
      "    Found existing installation: beautifulsoup4 4.12.2\r\n",
      "    Uninstalling beautifulsoup4-4.12.2:\r\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\r\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.0 aiosignal-1.3.2 aiosqlite-0.21.0 annotated-types-0.7.0 async-timeout-5.0.1 banks-2.1.2 beautifulsoup4-4.13.4 certifi-2025.4.26 charset-normalizer-3.4.2 click-8.1.8 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 eval-type-backport-0.2.2 filetype-1.2.0 frozenlist-1.6.0 fsspec-2025.5.1 greenlet-3.2.2 griffe-1.7.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 joblib-1.5.1 llama-cloud-0.1.22 llama-cloud-services-0.6.23 llama-index-0.12.37 llama-index-agent-openai-0.4.8 llama-index-cli-0.4.1 llama-index-core-0.12.37 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.11 llama-index-llms-ollama-0.5.6 llama-index-llms-openai-0.3.44 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.7 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.23 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.9.1 numpy-2.0.2 ollama-0.4.8 openai-1.82.0 pandas-2.2.3 pillow-11.2.1 platformdirs-4.3.8 propcache-0.3.1 pydantic-2.11.5 pydantic-core-2.33.2 pypdf-5.5.0 python-dotenv-1.1.0 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 sqlalchemy-2.0.41 striprtf-0.0.26 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspect-0.9.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.4.0 wrapt-1.17.2 yarl-1.20.0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\r\n",
      "You should consider upgrading via the '/Users/yohannesyimam/Documents/Projects/deffusion_model/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T03:36:35.206758Z",
     "start_time": "2025-05-25T03:36:33.828211Z"
    }
   },
   "cell_type": "code",
   "source": "pip install --upgrade typing_extensions # use python version >= 3.10 or update type extensions",
   "id": "923dc6ca14fdefe8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /Users/yohannesyimam/Documents/Projects/deffusion_model/venv/lib/python3.9/site-packages (4.13.2)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\r\n",
      "You should consider upgrading via the '/Users/yohannesyimam/Documents/Projects/deffusion_model/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T03:19:00.331308Z",
     "start_time": "2025-05-25T03:19:00.199304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.llms.ollama import Ollama"
   ],
   "id": "e07333381ba26d4f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# initialize local model",
   "id": "d0a66801af4a906d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T03:20:45.047166Z",
     "start_time": "2025-05-25T03:20:45.042460Z"
    }
   },
   "cell_type": "code",
   "source": "llm = Ollama(model=\"dagbs/qwen2.5-coder-7b-instruct-abliterated:latest\")",
   "id": "553304d8c68b3952",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## functions",
   "id": "b86fef65f3e90460"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T03:22:44.076889Z",
     "start_time": "2025-05-25T03:22:44.069350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"Multiply two numbers and return the result.\"\"\"\n",
    "    return a * b"
   ],
   "id": "bbc217166012d760",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T04:11:18.189098Z",
     "start_time": "2025-05-25T04:11:18.182801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\" a function that returns the weather data as a string value\"\"\"\n",
    "    url = \"https://api.weatherapi.com/v1/current.json\"\n",
    "    params = {\"key\": \"e40acd9bb9154ea499d34832252505\", \"q\": city, \"aqi\":\"no\"}\n",
    "\n",
    "    resp = requests.get(url, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        response_data = resp.json()\n",
    "        return response_data[\"current\"][\"condition\"][\"text\"]\n",
    "    else:\n",
    "        raise Exception(\"not data found\")\n",
    "    # return f\"The weather in {city} is sunny today.\""
   ],
   "id": "80d36df7ed06bb45",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## agent",
   "id": "547168fc55fe31bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T04:16:48.787388Z",
     "start_time": "2025-05-25T04:16:48.772227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    [FunctionTool.from_defaults(multiply),\n",
    "     FunctionTool.from_defaults(get_weather,\n",
    "                              name=\"my_weather_tool\",\n",
    "                              description=\"Useful for getting the weather for a given location.\")],\n",
    "    llm=llm\n",
    ")"
   ],
   "id": "c4fe978c55656752",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agents are stateless by default, add remembering past interactions is opt-in using a Context object This might be useful if you want to use an agent that needs to remember previous interactions, like a chatbot that maintains context across multiple messages or a task manager that needs to track progress over time.",
   "id": "a2dc5bc736bdf1f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# stateless\n",
    "response = await agent.run(\"What is 2 times 3?\")\n",
    "print(response)\n",
    "# remembering state\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(\"my name is john\", ctx=ctx)\n",
    "response = await agent.run(\"What was my name \", ctx=ctx)\n",
    "print(response)\n"
   ],
   "id": "ed7955d801f16ada",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T04:17:02.276672Z",
     "start_time": "2025-05-25T04:16:54.003046Z"
    }
   },
   "cell_type": "code",
   "source": "print(await agent.run(\"what is the weather in new york city?\"))",
   "id": "70f12c4613fb1a26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's currently overcast in New York City.\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "292338c06cb2da06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
